name: Booking.com Scraper

on:
  schedule:
    - cron: '0 */6 * * *'  # Run every 6 hours
  workflow_dispatch:  # Allow manual trigger

jobs:
  scrape:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Setup Node.js
      uses: actions/setup-node@v3
      with:
        node-version: '20'
        
    - name: Install dependencies
      run: npm install
      
    - name: Create credentials file
      run: |
        echo '${{ toJSON(secrets.BIGQUERY_CREDENTIALS) }}' > credentials.json
        cat credentials.json
      env:
        BIGQUERY_CREDENTIALS: ${{ secrets.BIGQUERY_CREDENTIALS }}
      
    - name: Run scraper
      run: node scraper.js
      env:
        GOOGLE_APPLICATION_CREDENTIALS: credentials.json 