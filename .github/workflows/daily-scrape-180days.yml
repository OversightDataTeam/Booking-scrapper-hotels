name: Daily 180 Days Scrape

on:
  schedule:
    - cron: '0 6 * * *'  # Exécution tous les jours à 6h du matin
  workflow_dispatch:  # Permet l'exécution manuelle

jobs:
  scrape:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Setup Node.js
      uses: actions/setup-node@v3
      with:
        node-version: '18'
        
    - name: Install dependencies
      run: npm install
        
    - name: Install Chrome
      run: |
        sudo apt-get update
        sudo apt-get install -y chromium-browser
        
    - name: Setup BigQuery credentials
      env:
        GOOGLE_APPLICATION_CREDENTIALS: ${{ secrets.GOOGLE_APPLICATION_CREDENTIALS }}
      run: |
        echo "$GOOGLE_APPLICATION_CREDENTIALS" > credentials.json
        
    - name: Run scraper2.js
      env:
        GOOGLE_APPLICATION_CREDENTIALS: credentials.json
      run: node scraper2.js
        
    - name: Configure Git
      run: |
        git config --global user.name 'GitHub Actions'
        git config --global user.email 'actions@github.com'
        
    - name: Commit and push if changes
      run: |
        git add .
        git diff --quiet && git diff --staged --quiet || (git commit -m "chore: Update data from scraper2.js" && git push) 