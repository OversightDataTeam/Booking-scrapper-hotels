# Booking.com Scraper - Google Cloud Function

Ce projet dÃ©ploie un scraper Booking.com en tant que Google Cloud Function avec intÃ©gration BigQuery et planification automatique via Cloud Scheduler.

## ðŸ—ï¸ Architecture

```
Google Cloud Scheduler (Cron) 
    â†“ (HTTP POST)
Google Cloud Function (Scraper)
    â†“ (Insert Data)
BigQuery (Storage)
```

## ðŸ“‹ PrÃ©requis

1. **Google Cloud SDK** installÃ© et configurÃ©
2. **Projet Google Cloud** avec les APIs suivantes activÃ©es :
   - Cloud Functions API
   - Cloud Scheduler API
   - BigQuery API
3. **Permissions** : Cloud Functions Admin, Cloud Scheduler Admin, BigQuery Admin

## ðŸš€ DÃ©ploiement

### 1. Configuration initiale

```bash
# Se connecter Ã  Google Cloud
gcloud auth login
gcloud config set project YOUR_PROJECT_ID

# Activer les APIs nÃ©cessaires
gcloud services enable cloudfunctions.googleapis.com
gcloud services enable cloudscheduler.googleapis.com
gcloud services enable bigquery.googleapis.com
```

### 2. DÃ©ploiement de la Cloud Function

```bash
cd cloud-function
./deploy.sh
```

### 3. Configuration du scheduler

```bash
./setup-scheduler.sh
```

## âš™ï¸ Configuration

### Variables d'environnement

CrÃ©ez un fichier `.env` basÃ© sur `env.example` :

```bash
cp env.example .env
# Ã‰ditez .env avec vos valeurs
```

### URLs Ã  scraper

Vous pouvez dÃ©finir les URLs de deux faÃ§ons :

1. **Variable d'environnement** (recommandÃ©) :
   ```bash
   gcloud functions deploy scrapeBookingData --set-env-vars SCRAPING_URLS="url1,url2,url3"
   ```

2. **Modification du code** dans `index.js` ligne 15-18

## ðŸ“Š BigQuery

### Structure de la table

La fonction crÃ©e automatiquement :
- **Dataset** : `booking_data`
- **Table** : `legal_info`

**SchÃ©ma** :
- `url` (STRING) : URL de l'hÃ´tel
- `businessName` (STRING) : Nom de l'entreprise
- `address` (STRING) : Adresse
- `email` (STRING) : Email
- `phone` (STRING) : TÃ©lÃ©phone
- `registerNumber` (STRING) : NumÃ©ro de registre du commerce
- `scrapedAt` (TIMESTAMP) : Date/heure du scraping
- `error` (STRING) : Message d'erreur si applicable

### RequÃªtes BigQuery utiles

```sql
-- Voir tous les rÃ©sultats
SELECT * FROM `your-project.booking_data.legal_info` 
ORDER BY scrapedAt DESC;

-- Compter les succÃ¨s vs erreurs
SELECT 
  COUNTIF(error IS NULL) as success_count,
  COUNTIF(error IS NOT NULL) as error_count
FROM `your-project.booking_data.legal_info`;

-- DerniÃ¨res donnÃ©es par hÃ´tel
SELECT 
  url,
  businessName,
  email,
  phone,
  scrapedAt
FROM `your-project.booking_data.legal_info`
WHERE error IS NULL
ORDER BY scrapedAt DESC;
```

## ðŸ”§ Gestion et monitoring

### Commandes utiles

```bash
# Voir les logs de la Cloud Function
gcloud functions logs read scrapeBookingData --region=europe-west1

# ExÃ©cuter manuellement le scraper
curl -X POST https://YOUR_FUNCTION_URL \
  -H "Content-Type: application/json" \
  -d '{"test": true}'

# Voir les jobs de scheduler
gcloud scheduler jobs list --location=europe-west1

# ExÃ©cuter manuellement le job
gcloud scheduler jobs run booking-scraper-daily --location=europe-west1

# Voir les logs BigQuery
gcloud logging read 'resource.type=bigquery_resource' --limit=20
```

### Monitoring dans la console

1. **Cloud Functions** : https://console.cloud.google.com/functions
2. **Cloud Scheduler** : https://console.cloud.google.com/cloudscheduler
3. **BigQuery** : https://console.cloud.google.com/bigquery

## ðŸ› ï¸ DÃ©veloppement local

Pour tester localement :

```bash
# Installer les dÃ©pendances
npm install

# Tester la fonction
node index.js
```

## ðŸ“ˆ Optimisations

### Performance
- **Timeout** : 540s (9 minutes) pour traiter plusieurs URLs
- **Memory** : 1GB pour Puppeteer
- **Concurrence** : Traitement sÃ©quentiel pour Ã©viter les blocages

### CoÃ»ts
- **Cloud Function** : Pay-per-use (trÃ¨s Ã©conomique)
- **BigQuery** : Stockage et requÃªtes payants
- **Cloud Scheduler** : 3 jobs gratuits par mois

## ðŸš¨ Limitations

1. **Rate limiting** : Booking.com peut bloquer les requÃªtes trop frÃ©quentes
2. **Timeout** : Maximum 9 minutes d'exÃ©cution
3. **Memory** : LimitÃ© Ã  1GB (suffisant pour Puppeteer)

## ðŸ”„ Mise Ã  jour

Pour mettre Ã  jour la fonction :

```bash
# Modifier le code
# Puis redÃ©ployer
./deploy.sh
```

## ðŸ†˜ DÃ©pannage

### Erreurs communes

1. **"Function timeout"** : RÃ©duire le nombre d'URLs ou optimiser le code
2. **"Permission denied"** : VÃ©rifier les permissions BigQuery
3. **"No business information found"** : Booking.com a changÃ© sa structure HTML

### Logs dÃ©taillÃ©s

```bash
# Logs en temps rÃ©el
gcloud functions logs tail scrapeBookingData --region=europe-west1

# Logs avec filtres
gcloud logging read 'resource.type=cloud_function AND severity>=ERROR' --limit=50
```

